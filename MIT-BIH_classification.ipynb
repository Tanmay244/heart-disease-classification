{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import get_model\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/mitbih_train.csv\", header = None)\n",
    "train = data.sample(frac = 1, random_state = 42)\n",
    "test = pd.read_csv(\"data/mitbih_test.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
       "1  0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
       "2  1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
       "3  0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
       "4  0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.890360</td>\n",
       "      <td>0.758160</td>\n",
       "      <td>0.423972</td>\n",
       "      <td>0.219104</td>\n",
       "      <td>0.201127</td>\n",
       "      <td>0.210399</td>\n",
       "      <td>0.205808</td>\n",
       "      <td>0.201773</td>\n",
       "      <td>0.198691</td>\n",
       "      <td>0.196757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.473376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240909</td>\n",
       "      <td>0.221813</td>\n",
       "      <td>0.227305</td>\n",
       "      <td>0.206878</td>\n",
       "      <td>0.177058</td>\n",
       "      <td>0.171909</td>\n",
       "      <td>0.178481</td>\n",
       "      <td>0.177240</td>\n",
       "      <td>0.171778</td>\n",
       "      <td>0.168357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044154</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>0.040525</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>0.037193</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.032865</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>1.143184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.921922</td>\n",
       "      <td>0.682486</td>\n",
       "      <td>0.250969</td>\n",
       "      <td>0.048458</td>\n",
       "      <td>0.082329</td>\n",
       "      <td>0.088416</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.068639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.991342</td>\n",
       "      <td>0.826013</td>\n",
       "      <td>0.429472</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.147878</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>0.145324</td>\n",
       "      <td>0.144424</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.148734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910506</td>\n",
       "      <td>0.578767</td>\n",
       "      <td>0.341727</td>\n",
       "      <td>0.258993</td>\n",
       "      <td>0.287628</td>\n",
       "      <td>0.298237</td>\n",
       "      <td>0.295391</td>\n",
       "      <td>0.290832</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  87554.000000  87554.000000  87554.000000  87554.000000  87554.000000   \n",
       "mean       0.890360      0.758160      0.423972      0.219104      0.201127   \n",
       "std        0.240909      0.221813      0.227305      0.206878      0.177058   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.921922      0.682486      0.250969      0.048458      0.082329   \n",
       "50%        0.991342      0.826013      0.429472      0.166000      0.147878   \n",
       "75%        1.000000      0.910506      0.578767      0.341727      0.258993   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  87554.000000  87554.000000  87554.000000  87554.000000  87554.000000   \n",
       "mean       0.210399      0.205808      0.201773      0.198691      0.196757   \n",
       "std        0.171909      0.178481      0.177240      0.171778      0.168357   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.088416      0.073333      0.066116      0.065000      0.068639   \n",
       "50%        0.158798      0.145324      0.144424      0.150000      0.148734   \n",
       "75%        0.287628      0.298237      0.295391      0.290832      0.283636   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...           178           179           180           181  \\\n",
       "count  ...  87554.000000  87554.000000  87554.000000  87554.000000   \n",
       "mean   ...      0.005025      0.004628      0.004291      0.003945   \n",
       "std    ...      0.044154      0.042089      0.040525      0.038651   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                182           183           184           185           186  \\\n",
       "count  87554.000000  87554.000000  87554.000000  87554.000000  87554.000000   \n",
       "mean       0.003681      0.003471      0.003221      0.002945      0.002807   \n",
       "std        0.037193      0.036255      0.034789      0.032865      0.031924   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                187  \n",
       "count  87554.000000  \n",
       "mean       0.473376  \n",
       "std        1.143184  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        4.000000  \n",
       "\n",
       "[8 rows x 188 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 87554)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    72471\n",
       "4.0     6431\n",
       "2.0     5788\n",
       "1.0     2223\n",
       "3.0      641\n",
       "Name: 187, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[len(train.columns)-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(train[len(train.columns)-1].values)\n",
    "X = np.array(train[list(range(len(train.columns)-1))])[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(test[len(train.columns)-1].values)\n",
    "X_test = np.array(test[list(range(len(test.columns)-1))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = ModelCheckpoint(filepath = \"model_initial.h5\", monitor = \"val_acc\", mode = 'max', save_best_only = True, verbose = 1)\n",
    "early = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 5, verbose = 1)\n",
    "redonplat = ReduceLROnPlateau(monitor = \"val_acc\", mode = \"max\", patience = 3, verbose = 2)\n",
    "\n",
    "callbacks_list = [chkpt, early, redonplat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ('/device:GPU:0',), variable_device = '/device:GPU:0'\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "\n",
    "print(f'Number of devices: {strategy.num_replicas_in_sync}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = get_model(X.shape[1], X.shape[2], data[len(train.columns)-1].nunique())\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer = opt, loss = tf.keras.losses.sparse_categorical_crossentropy, metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 187, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 183, 16)           96        \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 179, 16)           1296      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 89, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 89, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 87, 32)            1568      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 85, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 42, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 40, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 38, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 19, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 19, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 17, 256)           24832     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 271,157\n",
      "Trainable params: 271,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local Distribute Coordinator.\n",
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/10\n",
      "78592/78798 [============================>.] - ETA: 0s - loss: 0.4520 - acc: 0.8562\n",
      "Epoch 00001: val_acc improved from -inf to 0.91583, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 13s 159us/sample - loss: 0.4516 - acc: 0.8563 - val_loss: 0.2857 - val_acc: 0.9158\n",
      "Epoch 2/10\n",
      "78336/78798 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.9137\n",
      "Epoch 00002: val_acc improved from 0.91583 to 0.93433, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 6s 75us/sample - loss: 0.2913 - acc: 0.9139 - val_loss: 0.2319 - val_acc: 0.9343\n",
      "Epoch 3/10\n",
      "78336/78798 [============================>.] - ETA: 0s - loss: 0.2438 - acc: 0.9300\n",
      "Epoch 00003: val_acc improved from 0.93433 to 0.94724, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 6s 81us/sample - loss: 0.2439 - acc: 0.9299 - val_loss: 0.1883 - val_acc: 0.9472\n",
      "Epoch 4/10\n",
      "78080/78798 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9393\n",
      "Epoch 00004: val_acc improved from 0.94724 to 0.95443, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 6s 75us/sample - loss: 0.2130 - acc: 0.9394 - val_loss: 0.1652 - val_acc: 0.9544\n",
      "Epoch 5/10\n",
      "78720/78798 [============================>.] - ETA: 0s - loss: 0.1855 - acc: 0.9476\n",
      "Epoch 00005: val_acc improved from 0.95443 to 0.95866, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 6s 75us/sample - loss: 0.1855 - acc: 0.9476 - val_loss: 0.1469 - val_acc: 0.9587\n",
      "Epoch 6/10\n",
      "78464/78798 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9547\n",
      "Epoch 00006: val_acc improved from 0.95866 to 0.95980, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 6s 75us/sample - loss: 0.1648 - acc: 0.9547 - val_loss: 0.1381 - val_acc: 0.9598\n",
      "Epoch 7/10\n",
      "78080/78798 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9582\n",
      "Epoch 00007: val_acc improved from 0.95980 to 0.96574, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 6s 76us/sample - loss: 0.1494 - acc: 0.9582 - val_loss: 0.1222 - val_acc: 0.9657\n",
      "Epoch 8/10\n",
      "78464/78798 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9607\n",
      "Epoch 00008: val_acc improved from 0.96574 to 0.96951, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 6s 78us/sample - loss: 0.1394 - acc: 0.9608 - val_loss: 0.1103 - val_acc: 0.9695\n",
      "Epoch 9/10\n",
      "78592/78798 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9633\n",
      "Epoch 00009: val_acc improved from 0.96951 to 0.97145, saving model to model_initial.h5\n",
      "78798/78798 [==============================] - 6s 76us/sample - loss: 0.1313 - acc: 0.9633 - val_loss: 0.1074 - val_acc: 0.9714\n",
      "Epoch 10/10\n",
      "78208/78798 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9655\n",
      "Epoch 00010: val_acc did not improve from 0.97145\n",
      "78798/78798 [==============================] - 6s 75us/sample - loss: 0.1235 - acc: 0.9655 - val_loss: 0.1116 - val_acc: 0.9683\n",
      "WARNING:tensorflow:Skipped evaluation since `eval_fn` is not passed in.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size = 128, epochs = 10, verbose = 1, callbacks = callbacks_list, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.choice(X.shape[0])\n",
    "plt.plot(X[i].flatten())\n",
    "plt.title(\"Heartbeat Class: \" + str(Y[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.argmax(model.predict(X_test), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.8169160577564447 \n",
      "Test accuracy score : 0.9642791887447469 \n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, pred_test, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"MIT-BH.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
