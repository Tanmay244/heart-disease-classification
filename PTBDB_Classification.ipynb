{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import get_model\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11641, 188), (2911, 188))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv(\"data/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"data/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "train, test = train_test_split(df, test_size = 0.2, random_state = 42, stratify = df[len(df.columns)-1])\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900324</td>\n",
       "      <td>0.358590</td>\n",
       "      <td>0.051459</td>\n",
       "      <td>0.046596</td>\n",
       "      <td>0.126823</td>\n",
       "      <td>0.133306</td>\n",
       "      <td>0.119125</td>\n",
       "      <td>0.110616</td>\n",
       "      <td>0.113047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.375387</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171923</td>\n",
       "      <td>0.283859</td>\n",
       "      <td>0.293754</td>\n",
       "      <td>0.325912</td>\n",
       "      <td>0.345083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909029</td>\n",
       "      <td>0.791482</td>\n",
       "      <td>0.423169</td>\n",
       "      <td>0.186712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.063032</td>\n",
       "      <td>0.077002</td>\n",
       "      <td>0.074957</td>\n",
       "      <td>0.077342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478893</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.064176</td>\n",
       "      <td>0.081289</td>\n",
       "      <td>0.072732</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>0.048774</td>\n",
       "      <td>0.054478</td>\n",
       "      <td>0.041643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867238</td>\n",
       "      <td>0.201360</td>\n",
       "      <td>0.099349</td>\n",
       "      <td>0.141336</td>\n",
       "      <td>0.120934</td>\n",
       "      <td>0.108516</td>\n",
       "      <td>0.096393</td>\n",
       "      <td>0.093436</td>\n",
       "      <td>0.100828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.900324  0.358590  0.051459  0.046596  0.126823  0.133306   \n",
       "1  1.000000  0.794681  0.375387  0.116883  0.000000  0.171923  0.283859   \n",
       "2  0.909029  0.791482  0.423169  0.186712  0.000000  0.007836  0.063032   \n",
       "3  1.000000  0.478893  0.056760  0.064176  0.081289  0.072732  0.055619   \n",
       "4  1.000000  0.867238  0.201360  0.099349  0.141336  0.120934  0.108516   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.119125  0.110616  0.113047  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.293754  0.325912  0.345083  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.077002  0.074957  0.077342  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.048774  0.054478  0.041643  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.096393  0.093436  0.100828  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>14552.0</td>\n",
       "      <td>14552.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.976637</td>\n",
       "      <td>0.721663</td>\n",
       "      <td>0.403099</td>\n",
       "      <td>0.242893</td>\n",
       "      <td>0.207218</td>\n",
       "      <td>0.216453</td>\n",
       "      <td>0.221752</td>\n",
       "      <td>0.224486</td>\n",
       "      <td>0.227349</td>\n",
       "      <td>0.229704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.034532</td>\n",
       "      <td>0.195690</td>\n",
       "      <td>0.249794</td>\n",
       "      <td>0.249519</td>\n",
       "      <td>0.218097</td>\n",
       "      <td>0.192412</td>\n",
       "      <td>0.180740</td>\n",
       "      <td>0.176943</td>\n",
       "      <td>0.176674</td>\n",
       "      <td>0.176579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021361</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.624227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.959377</td>\n",
       "      <td>0.584589</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.052269</td>\n",
       "      <td>0.061875</td>\n",
       "      <td>0.090487</td>\n",
       "      <td>0.096503</td>\n",
       "      <td>0.097095</td>\n",
       "      <td>0.097231</td>\n",
       "      <td>0.097144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740148</td>\n",
       "      <td>0.371911</td>\n",
       "      <td>0.168148</td>\n",
       "      <td>0.136082</td>\n",
       "      <td>0.159451</td>\n",
       "      <td>0.167479</td>\n",
       "      <td>0.171541</td>\n",
       "      <td>0.177380</td>\n",
       "      <td>0.180337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881483</td>\n",
       "      <td>0.557785</td>\n",
       "      <td>0.336232</td>\n",
       "      <td>0.264104</td>\n",
       "      <td>0.264633</td>\n",
       "      <td>0.286484</td>\n",
       "      <td>0.302255</td>\n",
       "      <td>0.311664</td>\n",
       "      <td>0.325292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985523</td>\n",
       "      <td>0.993213</td>\n",
       "      <td>0.997738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791899</td>\n",
       "      <td>0.773743</td>\n",
       "      <td>0.789804</td>\n",
       "      <td>0.628177</td>\n",
       "      <td>0.602033</td>\n",
       "      <td>0.644880</td>\n",
       "      <td>0.371502</td>\n",
       "      <td>0.376668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  14552.000000  14552.000000  14552.000000  14552.000000  14552.000000   \n",
       "mean       0.976637      0.721663      0.403099      0.242893      0.207218   \n",
       "std        0.034532      0.195690      0.249794      0.249519      0.218097   \n",
       "min        0.624227      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.959377      0.584589      0.212300      0.052269      0.061875   \n",
       "50%        1.000000      0.740148      0.371911      0.168148      0.136082   \n",
       "75%        1.000000      0.881483      0.557785      0.336232      0.264104   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  14552.000000  14552.000000  14552.000000  14552.000000  14552.000000   \n",
       "mean       0.216453      0.221752      0.224486      0.227349      0.229704   \n",
       "std        0.192412      0.180740      0.176943      0.176674      0.176579   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.090487      0.096503      0.097095      0.097231      0.097144   \n",
       "50%        0.159451      0.167479      0.171541      0.177380      0.180337   \n",
       "75%        0.264633      0.286484      0.302255      0.311664      0.325292   \n",
       "max        1.000000      1.000000      0.985523      0.993213      0.997738   \n",
       "\n",
       "       ...           178           179           180           181  \\\n",
       "count  ...  14552.000000  14552.000000  14552.000000  14552.000000   \n",
       "mean   ...      0.001190      0.001133      0.000900      0.000739   \n",
       "std    ...      0.021361      0.021012      0.017316      0.014640   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      0.791899      0.773743      0.789804      0.628177   \n",
       "\n",
       "                182           183           184           185      186  \\\n",
       "count  14552.000000  14552.000000  14552.000000  14552.000000  14552.0   \n",
       "mean       0.000661      0.000475      0.000177      0.000185      0.0   \n",
       "std        0.014033      0.012289      0.006545      0.006835      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.0   \n",
       "max        0.602033      0.644880      0.371502      0.376668      0.0   \n",
       "\n",
       "                187  \n",
       "count  14552.000000  \n",
       "mean       0.721963  \n",
       "std        0.448047  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 188 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 11641)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    10506\n",
       "0.0     4046\n",
       "Name: 187, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[len(df.columns)-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(train[len(train.columns)-1].values)\n",
    "X = np.array(train[list(range(len(train.columns)-1))])[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(test[len(train.columns)-1].values)\n",
    "X_test = np.array(test[list(range(len(test.columns)-1))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = ModelCheckpoint(filepath = \"model_initial.h5\", monitor = \"val_acc\", mode = 'max', save_best_only = True, verbose = 1)\n",
    "early = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 5, verbose = 1)\n",
    "redonplat = ReduceLROnPlateau(monitor = \"val_acc\", mode = \"max\", patience = 3, verbose = 2)\n",
    "\n",
    "callbacks_list = [chkpt, early, redonplat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ('/device:GPU:0',), variable_device = '/device:GPU:0'\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "\n",
    "print(f'Number of devices: {strategy.num_replicas_in_sync}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = get_model(X.shape[1], 1, X.shape[2], 'sigmoid')\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer = opt, loss = tf.keras.losses.binary_crossentropy, metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 187, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 183, 16)           96        \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 179, 16)           1296      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 89, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 89, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 87, 32)            1568      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 85, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 42, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 40, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 38, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 19, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 19, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 17, 256)           24832     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 271,025\n",
      "Trainable params: 271,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local Distribute Coordinator.\n",
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/20\n",
      "10368/10476 [============================>.] - ETA: 0s - loss: 0.5426 - acc: 0.7181\n",
      "Epoch 00001: val_acc improved from -inf to 0.73219, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 9s 878us/sample - loss: 0.5415 - acc: 0.7182 - val_loss: 0.4814 - val_acc: 0.7322\n",
      "Epoch 2/20\n",
      "10368/10476 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.7632\n",
      "Epoch 00002: val_acc improved from 0.73219 to 0.84034, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 192us/sample - loss: 0.4461 - acc: 0.7637 - val_loss: 0.4211 - val_acc: 0.8403\n",
      "Epoch 3/20\n",
      "10304/10476 [============================>.] - ETA: 0s - loss: 0.3357 - acc: 0.8616\n",
      "Epoch 00003: val_acc improved from 0.84034 to 0.88755, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 205us/sample - loss: 0.3367 - acc: 0.8613 - val_loss: 0.2674 - val_acc: 0.8876\n",
      "Epoch 4/20\n",
      "10432/10476 [============================>.] - ETA: 0s - loss: 0.2714 - acc: 0.8947\n",
      "Epoch 00004: val_acc did not improve from 0.88755\n",
      "10476/10476 [==============================] - 2s 186us/sample - loss: 0.2709 - acc: 0.8948 - val_loss: 0.2646 - val_acc: 0.8815\n",
      "Epoch 5/20\n",
      "10432/10476 [============================>.] - ETA: 0s - loss: 0.2310 - acc: 0.9095\n",
      "Epoch 00005: val_acc improved from 0.88755 to 0.92446, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 186us/sample - loss: 0.2313 - acc: 0.9092 - val_loss: 0.1928 - val_acc: 0.9245\n",
      "Epoch 6/20\n",
      "10368/10476 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9208\n",
      "Epoch 00006: val_acc improved from 0.92446 to 0.94678, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 185us/sample - loss: 0.2045 - acc: 0.9213 - val_loss: 0.1476 - val_acc: 0.9468\n",
      "Epoch 7/20\n",
      "10176/10476 [============================>.] - ETA: 0s - loss: 0.1904 - acc: 0.9258\n",
      "Epoch 00007: val_acc did not improve from 0.94678\n",
      "10476/10476 [==============================] - 2s 181us/sample - loss: 0.1899 - acc: 0.9256 - val_loss: 0.1635 - val_acc: 0.9425\n",
      "Epoch 8/20\n",
      "10432/10476 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9318\n",
      "Epoch 00008: val_acc did not improve from 0.94678\n",
      "10476/10476 [==============================] - 2s 181us/sample - loss: 0.1720 - acc: 0.9320 - val_loss: 0.1412 - val_acc: 0.9433\n",
      "Epoch 9/20\n",
      "10368/10476 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9396\n",
      "Epoch 00009: val_acc improved from 0.94678 to 0.96309, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 203us/sample - loss: 0.1538 - acc: 0.9395 - val_loss: 0.1047 - val_acc: 0.9631\n",
      "Epoch 10/20\n",
      "10176/10476 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9514\n",
      "Epoch 00010: val_acc improved from 0.96309 to 0.97425, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 189us/sample - loss: 0.1298 - acc: 0.9524 - val_loss: 0.0847 - val_acc: 0.9742\n",
      "Epoch 11/20\n",
      "10176/10476 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9527\n",
      "Epoch 00011: val_acc did not improve from 0.97425\n",
      "10476/10476 [==============================] - 2s 180us/sample - loss: 0.1258 - acc: 0.9526 - val_loss: 0.0970 - val_acc: 0.9648\n",
      "Epoch 12/20\n",
      "10304/10476 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9530\n",
      "Epoch 00012: val_acc did not improve from 0.97425\n",
      "10476/10476 [==============================] - 2s 171us/sample - loss: 0.1194 - acc: 0.9529 - val_loss: 0.0849 - val_acc: 0.9742\n",
      "Epoch 13/20\n",
      "10112/10476 [===========================>..] - ETA: 0s - loss: 0.1026 - acc: 0.9630\n",
      "Epoch 00013: val_acc improved from 0.97425 to 0.98369, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 184us/sample - loss: 0.1029 - acc: 0.9627 - val_loss: 0.0548 - val_acc: 0.9837\n",
      "Epoch 14/20\n",
      "10432/10476 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9637\n",
      "Epoch 00014: val_acc did not improve from 0.98369\n",
      "10476/10476 [==============================] - 2s 167us/sample - loss: 0.0989 - acc: 0.9635 - val_loss: 0.0793 - val_acc: 0.9725\n",
      "Epoch 15/20\n",
      "10368/10476 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9633\n",
      "Epoch 00015: val_acc did not improve from 0.98369\n",
      "10476/10476 [==============================] - 2s 163us/sample - loss: 0.1020 - acc: 0.9633 - val_loss: 0.0731 - val_acc: 0.9760\n",
      "Epoch 16/20\n",
      "10304/10476 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9712\n",
      "Epoch 00016: val_acc did not improve from 0.98369\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "10476/10476 [==============================] - 2s 163us/sample - loss: 0.0804 - acc: 0.9715 - val_loss: 0.0628 - val_acc: 0.9811\n",
      "Epoch 17/20\n",
      "10112/10476 [===========================>..] - ETA: 0s - loss: 0.0582 - acc: 0.9781\n",
      "Epoch 00017: val_acc did not improve from 0.98369\n",
      "10476/10476 [==============================] - 2s 163us/sample - loss: 0.0575 - acc: 0.9785 - val_loss: 0.0424 - val_acc: 0.9820\n",
      "Epoch 18/20\n",
      "10240/10476 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9806\n",
      "Epoch 00018: val_acc improved from 0.98369 to 0.98455, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 204us/sample - loss: 0.0517 - acc: 0.9806 - val_loss: 0.0358 - val_acc: 0.9845\n",
      "Epoch 19/20\n",
      "10240/10476 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9825\n",
      "Epoch 00019: val_acc improved from 0.98455 to 0.98798, saving model to model_initial.h5\n",
      "10476/10476 [==============================] - 2s 182us/sample - loss: 0.0485 - acc: 0.9824 - val_loss: 0.0334 - val_acc: 0.9880\n",
      "Epoch 20/20\n",
      "10240/10476 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9834\n",
      "Epoch 00020: val_acc did not improve from 0.98798\n",
      "10476/10476 [==============================] - 2s 163us/sample - loss: 0.0471 - acc: 0.9833 - val_loss: 0.0354 - val_acc: 0.9880\n",
      "WARNING:tensorflow:Skipped evaluation since `eval_fn` is not passed in.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size = 64, epochs = 20, verbose = 1, callbacks = callbacks_list, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.choice(X.shape[0])\n",
    "plt.plot(X[i].flatten())\n",
    "plt.title(\"Heartbeat Class: \"+str(Y[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9914691943127963 \n",
      "Test accuracy score : 0.9876331157677773 \n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "pred_test = (pred_test > 0.5).astype(np.int8)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ptbdb.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
